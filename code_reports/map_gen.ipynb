{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22ac89a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import copy\n",
    "\n",
    "from grid_env_wrapper import GridEnvWrapper\n",
    "from grid_env import GridState, GridEnvironment\n",
    "from dqn import ResNetDQN, GraphDQN  \n",
    "import torch, torch.nn.functional as F\n",
    "from ppo import PPOActorCritic\n",
    "import random\n",
    "\n",
    "from collections import defaultdict, deque\n",
    "import heapq\n",
    "import itertools\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import datetime\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78870555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import copy\n",
    "from grid_env_wrapper import GridEnvWrapper  # adjust import as needed\n",
    "\n",
    "\n",
    "# 2) template env for grid formatting\n",
    "base_env = GridEnvWrapper(\n",
    "    grid_size=11,\n",
    "    variable_grid=False,\n",
    "    num_dynamic_obstacles=0,\n",
    "    generation_mode='maze',\n",
    "    maze_density=0.2\n",
    ")\n",
    "\n",
    "def save_datapoint_txts(pkl_path, out_dir, prefix):\n",
    "    with open(pkl_path, 'rb') as f:\n",
    "        data_list = pickle.load(f)\n",
    "    for idx, example in enumerate(data_list):\n",
    "        agent_envs = example['agent_envs']\n",
    "        # extract grid\n",
    "        base_env.env = copy.deepcopy(agent_envs[0].env)\n",
    "        grid = base_env.env.grid\n",
    "        rows, cols = grid.shape\n",
    "\n",
    "        # build lines\n",
    "        lines = [f\"{rows} {cols}\"]\n",
    "        for r in range(rows):\n",
    "            lines.append(\" \".join('@' if grid[r, c] == -1 else '.' for c in range(cols)))\n",
    "        lines.append(str(len(agent_envs)))\n",
    "        for env in agent_envs:\n",
    "            base_env.env = copy.deepcopy(env.env)\n",
    "            sr, sc = map(int, base_env.env.agent_pos)\n",
    "            gr, gc = map(int, base_env.env.goal_pos)\n",
    "            lines.append(f\"{sr} {sc} {gr} {gc}\")\n",
    "\n",
    "        # write to file\n",
    "        fname = f\"{prefix}_{idx}.txt\"\n",
    "        with open(os.path.join(out_dir, fname), 'w') as out:\n",
    "            out.write(\"\\n\".join(lines))\n",
    "\n",
    "# 3) iterate files 5 â†’ 20\n",
    "for i in range(5, 21):\n",
    "    pkl_file = os.path.join(\"simulation_data\", f\"simulation_datapoints_{i}.pkl\")\n",
    "    if os.path.isfile(pkl_file):\n",
    "        save_datapoint_txts(pkl_file, \"simulation_data/maps\", f\"map_{i}\")\n",
    "    else:\n",
    "        print(f\"Missing: {pkl_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e33db2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: simulation_data/simulation_datapoints_2wr_32.pkl\n",
      "Created output directory: simulation_data/maps_25x25_2\n",
      "Processing file: simulation_data/simulation_datapoints_2wr_64.pkl\n",
      "Processing file: simulation_data/simulation_datapoints_2wr_96.pkl\n",
      "\n",
      "Script finished.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import copy\n",
    "# Assuming GridEnvWrapper is in the same directory or accessible in PYTHONPATH\n",
    "# If not, you might need to adjust the import path, e.g., from your_project.grid_env_wrapper import GridEnvWrapper\n",
    "try:\n",
    "    from grid_env_wrapper import GridEnvWrapper\n",
    "except ImportError:\n",
    "    print(\"Error: Could not import GridEnvWrapper. Make sure it's in the correct path.\")\n",
    "    print(\"Please define a placeholder class if you want to proceed with a dummy GridEnvWrapper.\")\n",
    "    # Define a placeholder if the real one is not available for testing script logic\n",
    "    class GridEnvWrapper:\n",
    "        def __init__(self, grid_size, **kwargs):\n",
    "            print(f\"Dummy GridEnvWrapper initialized with grid_size: {grid_size}\")\n",
    "            self.grid_size = grid_size\n",
    "            # Mock a simple env structure for the script to run\n",
    "            class MockEnv:\n",
    "                def __init__(self, grid_size_val):\n",
    "                    self.grid = np.zeros((grid_size_val, grid_size_val)) # Example grid\n",
    "                    self.agent_pos = (0,0)\n",
    "                    self.goal_pos = (grid_size_val-1, grid_size_val-1)\n",
    "            self.env = MockEnv(grid_size)\n",
    "\n",
    "\n",
    "# Template environment for grid formatting for 21x21 grid\n",
    "# Adjust maze_density and other parameters if they differ for your 21x21 scenarios\n",
    "base_env_21x21 = GridEnvWrapper(\n",
    "    grid_size=25,  # Updated grid size\n",
    "    # variable_grid=False,\n",
    "    num_dynamic_obstacles=0,\n",
    "    generation_mode='warehouse', # Or whatever mode you used for 21x21\n",
    "    # maze_density=0.2 # Adjust if different for 21x21\n",
    ")\n",
    "\n",
    "def save_datapoint_txts(pkl_path, out_dir, prefix, expected_grid_size):\n",
    "    \"\"\"\n",
    "    Saves datapoints from a pickle file to text files in the specified format.\n",
    "\n",
    "    Args:\n",
    "        pkl_path (str): Path to the input .pkl file.\n",
    "        out_dir (str): Directory to save the output .txt files.\n",
    "        prefix (str): Prefix for the output filenames.\n",
    "        expected_grid_size (int): The expected grid size (e.g., 11 or 21) for this data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data_list = pickle.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Pickle file not found at {pkl_path}\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading pickle file {pkl_path}: {e}\")\n",
    "        return\n",
    "\n",
    "    if not os.path.exists(out_dir):\n",
    "        try:\n",
    "            os.makedirs(out_dir)\n",
    "            print(f\"Created output directory: {out_dir}\")\n",
    "        except OSError as e:\n",
    "            print(f\"Error creating output directory {out_dir}: {e}\")\n",
    "            return\n",
    "\n",
    "    for idx, example in enumerate(data_list):\n",
    "        if 'agent_envs' not in example or not example['agent_envs']:\n",
    "            print(f\"Warning: 'agent_envs' missing or empty in example {idx} from {pkl_path}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Use a base environment appropriate for the expected grid size\n",
    "        current_base_env = GridEnvWrapper(grid_size=expected_grid_size) # Re-init for safety or use a passed one\n",
    "        \n",
    "        # It's crucial that agent_envs[0].env.grid has the correct dimensions.\n",
    "        # We'll use the shape from the loaded data for robustness.\n",
    "        try:\n",
    "            # Deepcopy to avoid modifying the original loaded data\n",
    "            temp_env_data = copy.deepcopy(example['agent_envs'][0].env)\n",
    "            grid = temp_env_data.grid\n",
    "            rows, cols = grid.shape\n",
    "        except AttributeError:\n",
    "            print(f\"Warning: Could not access grid or its shape in example {idx} from {pkl_path}. Skipping.\")\n",
    "            continue\n",
    "        except IndexError:\n",
    "            print(f\"Warning: 'agent_envs' was empty in example {idx} from {pkl_path} after initial check. Skipping.\")\n",
    "            continue\n",
    "\n",
    "\n",
    "        # Validate grid size if necessary (optional, but good for sanity)\n",
    "        if rows != expected_grid_size or cols != expected_grid_size:\n",
    "            print(f\"Warning: Mismatch in example {idx} from {pkl_path}. Expected {expected_grid_size}x{expected_grid_size}, got {rows}x{cols}. Proceeding with loaded dimensions.\")\n",
    "            # Or you could choose to skip:\n",
    "            # print(f\"Skipping example {idx} due to grid size mismatch.\")\n",
    "            # continue\n",
    "\n",
    "\n",
    "        # Build lines for the text file\n",
    "        lines = [f\"{rows} {cols}\"]\n",
    "        for r in range(rows):\n",
    "            # Assuming -1 represents an obstacle ('@') and other values are traversable ('.')\n",
    "            lines.append(\" \".join('@' if grid[r, c] == -1 else '.' for c in range(cols)))\n",
    "        \n",
    "        lines.append(str(len(example['agent_envs'])))\n",
    "        \n",
    "        for agent_env_entry in example['agent_envs']:\n",
    "            try:\n",
    "                # It's safer to re-assign to a temporary env object or ensure deepcopy\n",
    "                current_base_env.env = copy.deepcopy(agent_env_entry.env)\n",
    "                sr, sc = map(int, current_base_env.env.agent_pos)\n",
    "                gr, gc = map(int, current_base_env.env.goal_pos)\n",
    "                lines.append(f\"{sr} {sc} {gr} {gc}\")\n",
    "            except AttributeError:\n",
    "                print(f\"Warning: Missing agent_pos or goal_pos in an agent_env for example {idx} from {pkl_path}.\")\n",
    "                # Decide how to handle this: skip agent, skip example, or add placeholder\n",
    "                lines.append(\"0 0 0 0 # Placeholder for missing agent data\") # Example placeholder\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Error processing agent data in example {idx} from {pkl_path}: {e}\")\n",
    "                lines.append(\"0 0 0 0 # Placeholder for error in agent data\") # Example placeholder\n",
    "\n",
    "\n",
    "        # Write to file\n",
    "        fname = f\"{prefix}_{idx}.txt\"\n",
    "        try:\n",
    "            with open(os.path.join(out_dir, fname), 'w') as out:\n",
    "                out.write(\"\\n\".join(lines))\n",
    "        except IOError as e:\n",
    "            print(f\"Error writing to file {os.path.join(out_dir, fname)}: {e}\")\n",
    "\n",
    "# Define agent counts for 21x21 grid processing\n",
    "agent_counts_21x21 = [32, 64, 96]\n",
    "grid_size_for_these_files = 25\n",
    "input_data_dir = \"simulation_data\" # Main directory where simulation_datapoints_AGENTCOUNT.pkl are\n",
    "output_maps_dir_21x21 = os.path.join(\"simulation_data\", \"maps_25x25_2\") # Specific output for these maps\n",
    "\n",
    "# print(f\"Processing for 21x21 grid, agent counts: {agent_counts_21x21}\")\n",
    "for num_agents in agent_counts_21x21:\n",
    "    # Construct the pickle file name based on the agent count\n",
    "    # This assumes your files are named like \"simulation_datapoints_32.pkl\", etc.\n",
    "    pkl_file = os.path.join(input_data_dir, f\"simulation_datapoints_2wr_{num_agents}.pkl\")\n",
    "    \n",
    "    if os.path.isfile(pkl_file):\n",
    "        print(f\"Processing file: {pkl_file}\")\n",
    "        # Define a prefix for the output files, e.g., \"map_21x21_32\"\n",
    "        output_prefix = f\"map_{num_agents}\"\n",
    "        save_datapoint_txts(pkl_file, output_maps_dir_21x21, output_prefix, grid_size_for_these_files)\n",
    "    else:\n",
    "        print(f\"Missing datapoint file: {pkl_file}\")\n",
    "\n",
    "# print(\"\\nProcessing for 11x11 grid (original loop) can be added back if needed.\")\n",
    "# Original loop for 5 to 20 agents (11x11 grid)\n",
    "# print(f\"\\nProcessing for 11x11 grid, agent counts: 5 to 20\")\n",
    "# grid_size_11x11 = 11\n",
    "# output_maps_dir_11x11 = os.path.join(\"simulation_data\", \"maps_11x11\") # Specific output for these maps\n",
    "# for i in range(5, 21):\n",
    "#     pkl_file_11x11 = os.path.join(input_data_dir, f\"simulation_datapoints_{i}.pkl\")\n",
    "#     if os.path.isfile(pkl_file_11x11):\n",
    "#         print(f\"Processing file: {pkl_file_11x11}\")\n",
    "#         output_prefix_11x11 = f\"map_{grid_size_11x11}x{grid_size_11x11}_{i}\"\n",
    "#         save_datapoint_txts(pkl_file_11x11, output_maps_dir_11x11, output_prefix_11x11, grid_size_11x11)\n",
    "#     else:\n",
    "#         print(f\"Missing datapoint file: {pkl_file_11x11}\")\n",
    "\n",
    "print(\"\\nScript finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5be3622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: simulation_data/den520d_8.pkl\n",
      "Created output directory: simulation_data/den520d_maps\n",
      "Warning: Mismatch in example 0 from simulation_data/den520d_8.pkl. Expected 32x32, got 257x257. Proceeding with loaded dimensions.\n",
      "Warning: Mismatch in example 1 from simulation_data/den520d_8.pkl. Expected 32x32, got 257x257. Proceeding with loaded dimensions.\n",
      "Warning: Mismatch in example 2 from simulation_data/den520d_8.pkl. Expected 32x32, got 257x257. Proceeding with loaded dimensions.\n",
      "Processing file: simulation_data/den520d_16.pkl\n",
      "Warning: Mismatch in example 0 from simulation_data/den520d_16.pkl. Expected 32x32, got 257x257. Proceeding with loaded dimensions.\n",
      "Warning: Mismatch in example 1 from simulation_data/den520d_16.pkl. Expected 32x32, got 257x257. Proceeding with loaded dimensions.\n",
      "Warning: Mismatch in example 2 from simulation_data/den520d_16.pkl. Expected 32x32, got 257x257. Proceeding with loaded dimensions.\n",
      "Processing file: simulation_data/den520d_32.pkl\n",
      "Warning: Mismatch in example 0 from simulation_data/den520d_32.pkl. Expected 32x32, got 257x257. Proceeding with loaded dimensions.\n",
      "Warning: Mismatch in example 1 from simulation_data/den520d_32.pkl. Expected 32x32, got 257x257. Proceeding with loaded dimensions.\n",
      "Warning: Mismatch in example 2 from simulation_data/den520d_32.pkl. Expected 32x32, got 257x257. Proceeding with loaded dimensions.\n",
      "Processing file: simulation_data/den520d_64.pkl\n",
      "Warning: Mismatch in example 0 from simulation_data/den520d_64.pkl. Expected 32x32, got 257x257. Proceeding with loaded dimensions.\n",
      "Warning: Mismatch in example 1 from simulation_data/den520d_64.pkl. Expected 32x32, got 257x257. Proceeding with loaded dimensions.\n",
      "Warning: Mismatch in example 2 from simulation_data/den520d_64.pkl. Expected 32x32, got 257x257. Proceeding with loaded dimensions.\n",
      "Processing file: simulation_data/den520d_96.pkl\n",
      "Warning: Mismatch in example 0 from simulation_data/den520d_96.pkl. Expected 32x32, got 257x257. Proceeding with loaded dimensions.\n",
      "Warning: Mismatch in example 1 from simulation_data/den520d_96.pkl. Expected 32x32, got 257x257. Proceeding with loaded dimensions.\n",
      "Warning: Mismatch in example 2 from simulation_data/den520d_96.pkl. Expected 32x32, got 257x257. Proceeding with loaded dimensions.\n",
      "\n",
      "Script finished.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import copy\n",
    "# Assuming GridEnvWrapper is in the same directory or accessible in PYTHONPATH\n",
    "# If not, you might need to adjust the import path, e.g., from your_project.grid_env_wrapper import GridEnvWrapper\n",
    "try:\n",
    "    from grid_env_wrapper import GridEnvWrapper\n",
    "except ImportError:\n",
    "    print(\"Error: Could not import GridEnvWrapper. Make sure it's in the correct path.\")\n",
    "    print(\"Please define a placeholder class if you want to proceed with a dummy GridEnvWrapper.\")\n",
    "    # Define a placeholder if the real one is not available for testing script logic\n",
    "    class GridEnvWrapper:\n",
    "        def __init__(self, grid_size, **kwargs):\n",
    "            print(f\"Dummy GridEnvWrapper initialized with grid_size: {grid_size}\")\n",
    "            self.grid_size = grid_size\n",
    "            # Mock a simple env structure for the script to run\n",
    "            class MockEnv:\n",
    "                def __init__(self, grid_size_val):\n",
    "                    self.grid = np.zeros((grid_size_val, grid_size_val)) # Example grid\n",
    "                    self.agent_pos = (0,0)\n",
    "                    self.goal_pos = (grid_size_val-1, grid_size_val-1)\n",
    "            self.env = MockEnv(grid_size)\n",
    "\n",
    "\n",
    "# Template environment for grid formatting for 21x21 grid\n",
    "# Adjust maze_density and other parameters if they differ for your 21x21 scenarios\n",
    "base_env_21x21 = GridEnvWrapper(\n",
    "    grid_size=32,  # Updated grid size\n",
    "    # variable_grid=False,\n",
    "    num_dynamic_obstacles=0,\n",
    "    generation_mode='warehouse', # Or whatever mode you used for 21x21\n",
    "    # maze_density=0.2 # Adjust if different for 21x21\n",
    ")\n",
    "\n",
    "def save_datapoint_txts(pkl_path, out_dir, prefix, expected_grid_size):\n",
    "    \"\"\"\n",
    "    Saves datapoints from a pickle file to text files in the specified format.\n",
    "\n",
    "    Args:\n",
    "        pkl_path (str): Path to the input .pkl file.\n",
    "        out_dir (str): Directory to save the output .txt files.\n",
    "        prefix (str): Prefix for the output filenames.\n",
    "        expected_grid_size (int): The expected grid size (e.g., 11 or 21) for this data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data_list = pickle.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Pickle file not found at {pkl_path}\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading pickle file {pkl_path}: {e}\")\n",
    "        return\n",
    "\n",
    "    if not os.path.exists(out_dir):\n",
    "        try:\n",
    "            os.makedirs(out_dir)\n",
    "            print(f\"Created output directory: {out_dir}\")\n",
    "        except OSError as e:\n",
    "            print(f\"Error creating output directory {out_dir}: {e}\")\n",
    "            return\n",
    "\n",
    "    for idx, example in enumerate(data_list):\n",
    "        if 'agent_envs' not in example or not example['agent_envs']:\n",
    "            print(f\"Warning: 'agent_envs' missing or empty in example {idx} from {pkl_path}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Use a base environment appropriate for the expected grid size\n",
    "        current_base_env = GridEnvWrapper(grid_size=expected_grid_size) # Re-init for safety or use a passed one\n",
    "        \n",
    "        # It's crucial that agent_envs[0].env.grid has the correct dimensions.\n",
    "        # We'll use the shape from the loaded data for robustness.\n",
    "        try:\n",
    "            # Deepcopy to avoid modifying the original loaded data\n",
    "            temp_env_data = copy.deepcopy(example['agent_envs'][0].env)\n",
    "            grid = temp_env_data.grid\n",
    "            rows, cols = grid.shape\n",
    "        except AttributeError:\n",
    "            print(f\"Warning: Could not access grid or its shape in example {idx} from {pkl_path}. Skipping.\")\n",
    "            continue\n",
    "        except IndexError:\n",
    "            print(f\"Warning: 'agent_envs' was empty in example {idx} from {pkl_path} after initial check. Skipping.\")\n",
    "            continue\n",
    "\n",
    "\n",
    "        # Validate grid size if necessary (optional, but good for sanity)\n",
    "        if rows != expected_grid_size or cols != expected_grid_size:\n",
    "            print(f\"Warning: Mismatch in example {idx} from {pkl_path}. Expected {expected_grid_size}x{expected_grid_size}, got {rows}x{cols}. Proceeding with loaded dimensions.\")\n",
    "            # Or you could choose to skip:\n",
    "            # print(f\"Skipping example {idx} due to grid size mismatch.\")\n",
    "            # continue\n",
    "\n",
    "\n",
    "        # Build lines for the text file\n",
    "        lines = [f\"{rows} {cols}\"]\n",
    "        for r in range(rows):\n",
    "            # Assuming -1 represents an obstacle ('@') and other values are traversable ('.')\n",
    "            lines.append(\" \".join('@' if grid[r, c] == -1 else '.' for c in range(cols)))\n",
    "        \n",
    "        lines.append(str(len(example['agent_envs'])))\n",
    "        \n",
    "        for agent_env_entry in example['agent_envs']:\n",
    "            try:\n",
    "                # It's safer to re-assign to a temporary env object or ensure deepcopy\n",
    "                current_base_env.env = copy.deepcopy(agent_env_entry.env)\n",
    "                sr, sc = map(int, current_base_env.env.agent_pos)\n",
    "                gr, gc = map(int, current_base_env.env.goal_pos)\n",
    "                lines.append(f\"{sr} {sc} {gr} {gc}\")\n",
    "            except AttributeError:\n",
    "                print(f\"Warning: Missing agent_pos or goal_pos in an agent_env for example {idx} from {pkl_path}.\")\n",
    "                # Decide how to handle this: skip agent, skip example, or add placeholder\n",
    "                lines.append(\"0 0 0 0 # Placeholder for missing agent data\") # Example placeholder\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Error processing agent data in example {idx} from {pkl_path}: {e}\")\n",
    "                lines.append(\"0 0 0 0 # Placeholder for error in agent data\") # Example placeholder\n",
    "\n",
    "\n",
    "        # Write to file\n",
    "        fname = f\"{prefix}_{idx}.txt\"\n",
    "        try:\n",
    "            with open(os.path.join(out_dir, fname), 'w') as out:\n",
    "                out.write(\"\\n\".join(lines))\n",
    "        except IOError as e:\n",
    "            print(f\"Error writing to file {os.path.join(out_dir, fname)}: {e}\")\n",
    "\n",
    "# Define agent counts for 21x21 grid processing\n",
    "agent_counts_21x21 = [8, 16, 32, 64, 96]\n",
    "grid_size_for_these_files = 32\n",
    "input_data_dir = \"simulation_data\" # Main directory where simulation_datapoints_AGENTCOUNT.pkl are\n",
    "output_maps_dir_21x21 = os.path.join(\"simulation_data\", \"den520d_maps\") # Specific output for these maps\n",
    "\n",
    "# print(f\"Processing for 21x21 grid, agent counts: {agent_counts_21x21}\")\n",
    "for num_agents in agent_counts_21x21:\n",
    "    # Construct the pickle file name based on the agent count\n",
    "    # This assumes your files are named like \"simulation_datapoints_32.pkl\", etc.\n",
    "    pkl_file = os.path.join(input_data_dir, f\"den520d_{num_agents}.pkl\")\n",
    "    \n",
    "    if os.path.isfile(pkl_file):\n",
    "        print(f\"Processing file: {pkl_file}\")\n",
    "        # Define a prefix for the output files, e.g., \"map_21x21_32\"\n",
    "        output_prefix = f\"map_{num_agents}\"\n",
    "        save_datapoint_txts(pkl_file, output_maps_dir_21x21, output_prefix, grid_size_for_these_files)\n",
    "    else:\n",
    "        print(f\"Missing datapoint file: {pkl_file}\")\n",
    "\n",
    "# print(\"\\nProcessing for 11x11 grid (original loop) can be added back if needed.\")\n",
    "# Original loop for 5 to 20 agents (11x11 grid)\n",
    "# print(f\"\\nProcessing for 11x11 grid, agent counts: 5 to 20\")\n",
    "# grid_size_11x11 = 11\n",
    "# output_maps_dir_11x11 = os.path.join(\"simulation_data\", \"maps_11x11\") # Specific output for these maps\n",
    "# for i in range(5, 21):\n",
    "#     pkl_file_11x11 = os.path.join(input_data_dir, f\"simulation_datapoints_{i}.pkl\")\n",
    "#     if os.path.isfile(pkl_file_11x11):\n",
    "#         print(f\"Processing file: {pkl_file_11x11}\")\n",
    "#         output_prefix_11x11 = f\"map_{grid_size_11x11}x{grid_size_11x11}_{i}\"\n",
    "#         save_datapoint_txts(pkl_file_11x11, output_maps_dir_11x11, output_prefix_11x11, grid_size_11x11)\n",
    "#     else:\n",
    "#         print(f\"Missing datapoint file: {pkl_file_11x11}\")\n",
    "\n",
    "print(\"\\nScript finished.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
